#-------- importing libraries -------

import pandas as pd
import os
import numpy as np
import seaborn as sns

data = pd.read_csv("C:/Users/PerezPeA/OneDrive - Unisys/Documents/Training/Representing, Processing, and Preparing Data/02/demos/mobile_price_classification.csv")
data.head()

#------ dataset information ----------
data.shape
data.columns
data.shape
data.describe()

#------- data cleaning operations --------

#delete the id column 
data = data.drop("id", axis=1)

#rename colomns 
data = data.rename(columns = {
    "blue" : "bluetooth",
    "fc" : "fc_megapixel",
    "pc" : "pc_megapixel",
    "m_dep" : "m_depth"})

#check for  duplicates
dupes = data.duplicated()
dupes.head()
sum(dupes) #question 1 : how many duplicated cells are in my data?
data = data.drop_duplicates() #delete duplicates in the dataset
dupes = data.duplicated()
dupes.head()
sum(dupes)
#checking for missing values
data.isnull().sum()#or data.isna().sum()---- # question 2 : how many missing values are in my dataset
#-----------
#colomns  with missing values - dual_sim - fc_megapixel - ram - 
#-----------
len(data['ram'].unique()) #how many unique  values are in my colomn
#filling missing data
data['ram'] = data['ram'].fillna(method='backfill') #backfill and mean are two of the methodes for fill missing  data
len(data['ram'].unique())

data.isnull().sum()

data['mobile_wt'] = data['mobile_wt'].fillna(data['mobile_wt'].median())
data.isnull().sum()

data = data.dropna()
data.isnull().sum().describe()


data.shape

#-----------------------------------------------------------

#save this clean detaset ---------------

data.to_csv('mobile_data_cleaned.csv', index = False)

##################################################################################
##################################################################################

#---------------------------------------------------------------------------------

# IDENTIFIYING OUTLIERS 


#----------------------------------------------

#we  clasify the  data  in numeric data  and categorical data
#numeric data
data.columns
numeric_data = data.drop(['bluetooth', 'dual_sim', 'four_g', 'three_g', 'touch_screen', 'wifi', 'price_range'], axis=1)
numeric_data.head()
#categorical data
categorical_data = data.drop(numeric_data, axis=1)
categorical_data.head()

#visualization of outliers
#---------libraries--------
from matplotlib import pyplot as plt
import seaborn as sns
#ram colomn 
fig, ax = plt.subplots(figsize = (10, 8))
sns.boxplot(numeric_data['ram'], 
                    orient= 'v')
plt.show()

#mobile_wt colomn
fig, ax = plt.subplot(figsize = (10, 8))

sns.boxenplot(numeric_data['mobile_wt'],
                orient='v')

plt.show()

#all the  colomns

fig, ax = plt.subplot(figsize = (10, 8))

bp = sns.boxenplot(data=numeric_data)

bp.set_xticklabels(bp.get_xticklabels(), rotation=90)

plt.show()

# location of outliers standarizing  data

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaled_array = scaler.fit_transform(numeric_data) #scale the numeric data  to have zero mean and unit variance

scaled_data = pd.DataFrame(scaled_array, columns = numeric_data.columns) #we create a new  dataframe  with the  array created in the  previous  step
scaled_data.head()

scaled_data.describe()

#########------------------------------
#plot with all the standarized  colomns 

fig, ax = plt.subplot(figsize = (10, 8))

bp = sns.boxenplot(data= scaled_data)

bp.set_xticklabels(bp.get_xticklabels(), rotation=90)

plt.show()


#remove outliers

Q1 = numeric_data.quantile(0.25)
Q3 = numeric_data.quantile(0.75)

IQR = Q3 - Q1

print(IQR)

############### removing  the  outliers
outliers_removed_data = numeric_data[~ ((numeric_data < (Q1 - 1.5 * IQR)) \
                                     | (numeric_data > (Q3 + 1.5 * IQR))).any(axis=1)]

outliers_removed_data.shape
numeric_data.shape

#ploting the data
fig, ax =  plt.subplot(figsize = (10, 8))

bp = sns.boxenplot(data= outliers_removed_data)

bp.set_xticklabels(bp.get_xticklabels(), rotation=90)
plt.show()
 


######################################################################################
#------------------------------------------------------------------------------------

#TRAING A  CLASIFICATION MODULE 

from sklearn.model_selection import train_test_split

scaled_data = scaled_data.reset_index()
categorical_data = categorical_data.reset_index()
final_df = pd.concat([scaled_data, categorical_data], axis=1)

final_df.isnull().sum()

x = final_df.drop('price_range', axis=1)

y = final_df['price_range']

x_train, x_test, y_train, y_test = train_test_split(x, y,
                                                        test_size= 0.20,
                                                        random_state= 101)


from sklearn.linear_model import LogisticRegression

logistic_model = LogisticRegression(solver = 'lbfgs',
                                        multi_class='multinomial',
                                        max_iter=10000)


logistic_model.fit(x_train, y_train)
logistic_model.score(x_test, y_test)


